{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "969f761b",
   "metadata": {},
   "source": [
    "<h1> <u> <font color= green > ML_Assignment_4 </font> </u> </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d0fafc",
   "metadata": {},
   "source": [
    "## 1. What are the key tasks involved in getting ready to work with machine learning modeling?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c6a034",
   "metadata": {},
   "source": [
    "> For getting ready to work with machine learning modeling, the following should be considered:\n",
    "> 1. **Define the problem**: The first step is to define the problem that we want to solve with machine learning. What is the goal of the machine learning model? What data do we have available? What are the constraints on the model?\n",
    "> 2. **Gather data**: Once the problem is defined, we need to gather the data that we will use to train the machine learning model. The data should be relevant to the problem that we are trying to solve, and it should be of high quality.\n",
    "> 3. **Clean and prepare the data**: The data that we gather may not be ready to use directly for training the machine learning model. we may need to clean the data, remove outliers, and transform the data into a format that the machine learning algorithm can understand.\n",
    "> 4. **Choose a machine learning algorithm**: There are many different machine learning algorithms available. The best algorithm for our problem will depend on the type of data that we have, the complexity of the problem, and the constraints on the model.\n",
    "> 5. **Train the model**: Once we have chosen a machine learning algorithm, we need to train the model on the data that we gathered. The training process involves the algorithm learning the patterns in the data and how to use those patterns to make predictions.\n",
    "> 6. **Evaluate the model**: Once the model is trained, we need to evaluate the model's performance. This is done by testing the model on a holdout dataset that was not used for training. The evaluation results will help us to determine whether the model is ready to be used in production.\n",
    "> 7. **Deploy the model**: If the model's performance is satisfactory, we can deploy the model in production. This means that the model will be used to make predictions on new data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a2acd5",
   "metadata": {},
   "source": [
    "## 2. What are the different forms of data used in machine learning? Give a specific example for each of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3048e84f",
   "metadata": {},
   "source": [
    "> There are many different forms of data that can be used in machine learning. Some of the most common types of data include:\n",
    "> * **Numerical data**: Numerical data is data that can be represented as numbers. For example, the price of a house, the number of sales that a company makes, and the number of times that a user clicks on a button are all examples of numerical data.\n",
    "> * **Categorical data**: Categorical data is data that can be categorized into different groups. For example, the color of a car, the type of pet that a person owns, and the political party that a person supports are all examples of categorical data.\n",
    "> * **Text data**: Text data is data that is represented as text. For example, the text of a book, the code of a website, and the tweets of a user are all examples of text data.\n",
    "> * **Image data**: Image data is data that is represented as images. For example, the images of a cat, the images of a dog, and the images of a sunset are all examples of image data.\n",
    "> * **Audio data**: Audio data is data that is represented as audio. For example, the audio of a song, the audio of a speech, and the audio of a conversation are all examples of audio data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0495e924",
   "metadata": {},
   "source": [
    "## 3. Distinguish:\n",
    "        1. Numeric vs. categorical attributes\n",
    "        2. Feature selection vs. dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b81f2c",
   "metadata": {},
   "source": [
    "<b><i> Numeric vs. categorical attributes </i></b>\n",
    "> * **Numeric attributes**: Numeric attributes are data points that can be represented as numbers. For example, the price of a house, the number of sales that a company makes, and the number of times that a user clicks on a button are all examples of numeric attributes.\n",
    "> * **Categorical attributes**: Categorical attributes are data points that can be categorized into different groups. For example, the color of a car, the type of pet that a person owns, and the political party that a person supports are all examples of categorical attributes.\n",
    "\n",
    "> The main difference between numeric and categorical attributes is that **numeric attributes** can be ordered, while **categorical attributes** cannot. For example, the price of a house can be ordered from lowest to highest, but the color of a car cannot.\n",
    "---\n",
    "<b><i> Feature selection vs. dimensionality reduction </i></b> \n",
    "> * **Feature selection**: Feature selection is the process of selecting a subset of features from a dataset that are most relevant to the problem that is being solved. Feature selection can be used to improve the performance of machine learning models by reducing the noise in the data and focusing on the most important features.\n",
    "> * **Dimensionality reduction**: Dimensionality reduction is the process of reducing the number of features in a dataset without losing too much information. Dimensionality reduction can be used to make machine learning models more interpretable and to improve the performance of machine learning models by reducing the complexity of the data.\n",
    "\n",
    "> The main difference between feature selection and dimensionality reduction is that **feature selection** is a process of selecting a subset of features, while **dimensionality reduction** is a process of reducing the number of features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27999e46",
   "metadata": {},
   "source": [
    "## 4. Make quick notes on any two of the following:\n",
    "        1. The histogram\n",
    "        2. Use a scatter plot\n",
    "        3. PCA (Principal Component Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7c1f5f",
   "metadata": {},
   "source": [
    "<b><i> Histogram </i></b>\n",
    "> * A **histogram** is a graphical representation of the distribution of data. It is a bar graph that shows the frequency of each value in a dataset. Histograms are often used to visualize the distribution of continuous data, such as the height of people or the weight of dogs.\n",
    "> * To create a histogram, we first need to create a list of all the values in your dataset. Then, we need to count the number of times each value appears in the dataset. Finally, we need to create a bar graph that shows the frequency of each value.\n",
    "> * The height of each bar in a histogram represents the frequency of the corresponding value in the dataset. The width of each bar is usually equal to the width of the smallest possible value in the dataset.\n",
    "> * Histograms are a useful tool for visualizing the distribution of data. They can help us to identify the shape of the distribution, the range of values in the dataset, and the outliers in the dataset.\n",
    "\n",
    "<b><i> Scatter plot </i></b> \n",
    "> * A **scatter plot** is a graphical representation of the relationship between two variables. It is a two-dimensional graph that shows the value of one variable on the x-axis and the value of the other variable on the y-axis.\n",
    "> * To create a scatter plot, we first need to create two lists of values. One list will contain the values of the x-variable, and the other list will contain the values of the y-variable. Then, we need to plot each point in the dataset as a point on the graph.\n",
    "> * The points in a scatter plot can be used to visualize the relationship between the two variables. If the points are scattered randomly, then there is no clear relationship between the two variables. However, if the points are clustered together, then there is a clear relationship between the two variables.\n",
    "> * Scatter plots are a useful tool for visualizing the relationship between two variables. They can help us to identify the strength of the relationship, the direction of the relationship, and the outliers in the dataset.\n",
    "\n",
    "<b><i> PCA (Principal Component Analysis) </i></b> \n",
    "> * **Principal component analysis (PCA)** is a statistical procedure that transforms a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables called principal components.\n",
    "> * PCA is a powerful tool for dimensionality reduction, which is the process of reducing the number of variables in a dataset without losing too much information. PCA can be used to make machine learning models more interpretable and to improve the performance of machine learning models by reducing the complexity of the data.\n",
    "> * PCA works by finding the directions in the data that contain the most variation. These directions are called principal components. The principal components are ordered by the amount of variation that they explain. The first principal component explains the most variation in the data, the second principal component explains the second most variation, and so on.\n",
    "> * PCA can be used to reduce the dimensionality of a dataset by selecting a subset of the principal components. The number of principal components that are selected will depend on the specific problem that is being solved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f62fb57",
   "metadata": {},
   "source": [
    "## 5. Why is it necessary to investigate data? Is there a discrepancy in how qualitative and quantitative data are explored?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a0cb75",
   "metadata": {},
   "source": [
    "> It is necessary to investigate data because data is the foundation of any decision-making process. Data can help us to understand the world around us, identify trends, and make informed decisions.\n",
    "\n",
    "> There are two main types of data: quantitative and qualitative.  \n",
    "> * **Quantitative data** is numerical data that can be measured and counted. Quantitative data is typically explored using statistical methods, such as regression analysis, correlation analysis, and hypothesis testing. \n",
    "> * **Qualitative data** is non-numerical data that describes things in words. Qualitative data is typically explored using methods such as thematic analysis, content analysis, and discourse analysis.\n",
    "\n",
    "> There are some discrepancies in how qualitative and quantitative data are explored. For example, **quantitative data** is typically analyzed using statistical software, while **qualitative data** is typically analyzed using qualitative analysis software. Additionally, quantitative data is typically presented in tables and graphs, while qualitative data is typically presented in text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56c7673",
   "metadata": {},
   "source": [
    "## 6. What are the various histogram shapes? What exactly are ‘bins'?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77e468b",
   "metadata": {},
   "source": [
    "<b><i> Histogram shapes </i></b> \n",
    "> A **histogram** is a graphical representation of the distribution of data. It is a bar graph that shows the frequency of each value in a dataset. The shape of a histogram can tell us a lot about the distribution of the data.\n",
    "\n",
    "> Here are some of the most common histogram shapes:\n",
    "> * **Normal distribution**: A normal distribution is a bell-shaped curve that is often seen in nature. It is the most common type of histogram shape.\n",
    "> * **Uniform distribution**: A uniform distribution is a histogram where the values are evenly distributed.    \n",
    "> * **Bimodal distribution**: A bimodal distribution is a histogram where there are two peaks.\n",
    "> * **Trimodal distribution**: A trimodal distribution is a histogram where there are three peaks.\n",
    "> * **Poisson distribution**: A Poisson distribution is a histogram where the values are rare and unpredictable.\n",
    "\n",
    "---\n",
    "\n",
    "<b><i> Bins </i></b>\n",
    "> In a histogram, the data is divided into bins. A **bin** is a range of values that are grouped together. The width of the bins determines the granularity of the histogram. For example, if the data is divided into 10 bins, then each bin will represent 10% of the data. If the data is divided into 100 bins, then each bin will represent 1% of the data.\n",
    "\n",
    "> The **width of the bins** is important because it affects the shape of the histogram. If the bins are too wide, then the histogram will be smoothed out. If the bins are too narrow, then the histogram will be too granular.\n",
    "\n",
    "> The best way to choose the **width of the bins** is to experiment and see what looks best for the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144ca78a",
   "metadata": {},
   "source": [
    "## 7. How do we deal with data outliers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e2e646",
   "metadata": {},
   "source": [
    "> **Data outliers** are data points that are significantly different from the rest of the data in a dataset. They can be caused by a variety of factors, such as <b><i> measurement errors, data entry errors, or simply random variation. </i></b>\n",
    "\n",
    "> **Outliers** can distort the distribution of data and make it difficult to analyze. There are a number of ways to deal with data outliers, some of them are:\n",
    "> * **Identifying and removing outliers**: This is the most common approach to dealing with outliers. Outliers can be identified using a variety of methods, such as the interquartile range (IQR) rule or the Grubbs test. Once outliers have been identified, they can be removed from the dataset.\n",
    "> * **Treating outliers as missing data**: This approach involves treating outliers as missing data points. This can be done by simply deleting the outliers or by replacing them with the mean or median of the dataset.\n",
    "> * **Incorporating outliers into the analysis**: This approach involves incorporating outliers into the analysis by adjusting the statistical methods that are used. For example, outliers can be incorporated into a regression analysis by using robust regression methods.\n",
    "\n",
    ">The best approach to dealing with data outliers will depend on the specific dataset and the purpose of the analysis. If the outliers are caused by measurement errors or data entry errors, then they should be removed from the dataset. However, if the outliers are simply random variation, then they may be better treated as missing data or incorporated into the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323c62e6",
   "metadata": {},
   "source": [
    "## 8. What are the various central inclination measures? Why does mean vary too much from median in certain data sets?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c4b898",
   "metadata": {},
   "source": [
    "<b><i> Central inclination measures </i></b>\n",
    "> There are several measures of central tendency that can be used to describe the center of a dataset. These measures include:\n",
    "> * **Mean**: The mean is the average of all the values in a dataset. It is calculated by adding all the values in the dataset and then dividing by the number of values.\n",
    "> * **Median**: The median is the middle value in a dataset when all the values are arranged in order from least to greatest. If there is an even number of values in the dataset, then the median is the average of the two middle values.\n",
    "> * **Mode**: The mode is the most frequent value in a dataset. It is the value that appears most often in the dataset.\n",
    "\n",
    "<b><i> Why does mean vary too much from median in certain data sets? </i></b>\n",
    "> The mean can vary too much from the median in certain datasets because of the **presence of outliers**. **Outliers** are data points that are significantly different from the rest of the data in a dataset. They can cause the mean to be pulled in their direction, which can distort the distribution of the data.\n",
    "\n",
    "> For example, consider a dataset that contains the heights of all the students in a class. If there is one student who is very tall, then the mean height of the class will be pulled up by that student. However, the median height of the class will not be affected by that student, because the median is only concerned with the middle value in the dataset.\n",
    "\n",
    "> In general, the **mean is more sensitive to outliers** than the median. This is because the mean is calculated by taking all the values in the dataset and averaging them, while the median is only concerned with the middle value in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b13fc1",
   "metadata": {},
   "source": [
    "## 9. Describe how a scatter plot can be used to investigate bivariate relationships. Is it possible to find outliers using a scatter plot?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900d744e",
   "metadata": {},
   "source": [
    "> A **scatter plot** is a graphical representation of the relationship between two variables. It is a two-dimensional graph that shows the value of one variable on the x-axis and the value of the other variable on the y-axis.\n",
    "\n",
    "> **Scatter plots** can be used to investigate <b><i> bivariate relationships </i></b> by looking for patterns in the way that the points are distributed on the graph. For example, if the points are clustered together in a line, then there is a positive correlation between the two variables. If the points are clustered together in a line that slopes downwards, then there is a negative correlation between the two variables.\n",
    "\n",
    "> **Outliers** can also be identified using scatter plots. **Outliers** are data points that are significantly different from the rest of the data in a dataset. They can be identified by looking for points that are far away from the rest of the data points.\n",
    "---\n",
    "> Here are some of the things that can be investigated using a scatter plot:\n",
    "> * **The strength of the relationship**: The strength of the relationship between two variables can be determined by looking at how close the points are to the line of best fit. If the points are tightly clustered around the line of best fit, then the relationship is strong. If the points are more spread out, then the relationship is weaker.\n",
    "> * **The direction of the relationship**: The direction of the relationship between two variables can be determined by looking at the slope of the line of best fit. If the slope is positive, then there is a positive correlation between the two variables. If the slope is negative, then there is a negative correlation between the two variables.\n",
    "> * **The presence of outliers**: Outliers can be identified by looking for points that are far away from the rest of the data points. Outliers can be caused by a variety of factors, such as measurement errors, data entry errors, or simply random variation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d88b3de",
   "metadata": {},
   "source": [
    "## 10. Describe how cross-tabs can be used to figure out how two variables are related."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92845bca",
   "metadata": {},
   "source": [
    "> A **cross-tab** is a table that shows the distribution of two variables simultaneously. It is a useful tool for investigating the relationship between two variables, especially when the variables are categorical.\n",
    "\n",
    "> To **create a cross-tab**, we first need to create two lists of values. One list will contain the values of the x-variable, and the other list will contain the values of the y-variable. Then, we need to count the number of times each combination of values appears in the dataset. <br>\n",
    "> The **cross-tab** will show us how the two variables are related. For example, if the x-variable is gender and the y-variable is political affiliation, the cross-tab will show us how men and women are distributed across the different political affiliations.\n",
    "\n",
    "<b><i> The following things can be investigated using cross-tabs: </i></b>\n",
    "> * **The strength of the relationship**: The strength of the relationship between two variables can be determined by looking at the number of cells in the cross-tab that have a high frequency. If there are many cells with a high frequency, then the relationship is strong. If there are few cells with a high frequency, then the relationship is weaker.\n",
    "> * **The direction of the relationship**: The direction of the relationship between two variables can be determined by looking at the values in the cross-tab. If the values in the cross-tab increase as the values in the x-variable increase, then there is a positive correlation between the two variables. If the values in the cross-tab decrease as the values in the x-variable increase, then there is a negative correlation between the two variables.\n",
    "> * **The presence of outliers**: Outliers can be identified by looking for cells in the cross-tab that have a very low or very high frequency. Outliers can be caused by a variety of factors, such as measurement errors, data entry errors, or simply random variation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebb3aa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6f49d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
