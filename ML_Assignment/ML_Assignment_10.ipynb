{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "969f761b",
   "metadata": {},
   "source": [
    "<h1> <u> <font color= green > ML_Assignment_10 </font> </u> </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482f0292",
   "metadata": {},
   "source": [
    "## 1. Define the Bayesian interpretation of probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358b7c9b",
   "metadata": {},
   "source": [
    "> The **Bayesian interpretation of probability** is a way of understanding probability that is based on the idea of degrees of belief. In this interpretation, probability is a measure of how strongly we believe that something is true.\n",
    "\n",
    "> The Bayesian interpretation of probability is based on the following two principles:\n",
    "> * **Prior probability**: The prior probability of an event is your belief about the probability of the event before you have any evidence.\n",
    "> * **Posterior probability**: The posterior probability of an event is your belief about the probability of the event after you have seen some evidence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb158a5",
   "metadata": {},
   "source": [
    "## 2. Define probability of a union of two events with equation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e38ba72",
   "metadata": {},
   "source": [
    "> The **probability of the union of two events**, denoted as P(A ∪ B), is the probability that at least one of the two events A or B occurs. Mathematically, the equation for the probability of the union of two events is: <br>\n",
    "```P(A∪B) = P(A) + P(B) - P(A∩B)```\n",
    "\n",
    "            where:\n",
    "                P(A∪B) is the probability of the union of events A and B.\n",
    "                P(A) is the probability of event A.\n",
    "                P(B) is the probability of event B.\n",
    "                P(A∩B) is the probability of events A and B occurring together.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bdbf64",
   "metadata": {},
   "source": [
    " ## 3. What is joint probability? What is its formula?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2031e6",
   "metadata": {},
   "source": [
    "> **Joint probability** refers to the probability of two or more events occurring simultaneously or together. It measures the likelihood of the intersection or overlap of multiple events happening at the same time.\n",
    "\n",
    "> The formula for joint probability depends on whether the events are independent or dependent: <br>\n",
    "> 1. **Independent Events**:\n",
    "    If events A and B are independent, meaning that the occurrence of one event does not affect the probability of the other event, the joint probability is calculated by multiplying the individual probabilities of the events: <br>\n",
    "```P(A ∩ B) = P(A) * P(B)```\n",
    "\n",
    "> 2. **Dependent Events**:\n",
    "    If events A and B are dependent, meaning that the occurrence of one event affects the probability of the other event, the joint probability is calculated by multiplying the conditional probability of one event given the occurrence of the other event: <br>\n",
    "```P(A ∩ B) = P(A | B) * P(B)```\n",
    "\n",
    "            where:\n",
    "                P(A ∩ B) is the joint probability of events A and B.\n",
    "                P(A) and P(B) are the individual probabilities of events A and B, respectively.\n",
    "                P(A | B) is the conditional probability of event A given event B."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98177d6",
   "metadata": {},
   "source": [
    "## 4. What is chain rule of probability?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766eda13",
   "metadata": {},
   "source": [
    "> The **chain rule of probability** is a formula that is used to calculate the probability of multiple events occurring in a sequence.\n",
    "> The chain rule of probability is stated as follows: <br>\n",
    "```P(A ∩ B ∩ C) = P(A) * P(B|A) * P(C|A∩B)```\n",
    "\n",
    "            where:\n",
    "                P(A ∩ B ∩ C) is the probability of events A, B, and C occurring together.\n",
    "                P(A) is the probability of event A occurring.\n",
    "                P(B|A) is the conditional probability of event B occurring given that event A has already occurred.\n",
    "                P(C|A∩B) is the conditional probability of event C occurring given that events A and B have already occurred.\n",
    "\n",
    "> The chain rule of probability can be extended to any number of events. For example, the probability of events A, B, C, and D occurring together can be calculated using the following formula:<br>\n",
    "```P(A ∩ B ∩ C ∩ D) = P(A) * P(B|A) * P(C|A∩B) * P(D|A∩B∩C)```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a435c86f",
   "metadata": {},
   "source": [
    "## 5. What is conditional probability means? What is the formula of it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c40309",
   "metadata": {},
   "source": [
    "> **Conditional probability** is the probability of one event occurring given that another event has already occurred. It is calculated using the following formula: <br>\n",
    "```P(B|A) = P(A∩B)/P(A)```\n",
    "\n",
    "            where:\n",
    "                P(B|A) is the conditional probability of event B occurring given that event A has already occurred.\n",
    "                P(A∩B) is the joint probability of events A and B. = P(A)P(B|A)\n",
    "                P(A) is the probability of event A.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f22504",
   "metadata": {},
   "source": [
    "## 6. What are continuous random variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29283cc5",
   "metadata": {},
   "source": [
    "> A **continuous random variable** is a random variable that can take on an infinite number of possible values. The probability of a continuous random variable taking on a particular value is zero, but the probability of it taking on a value within a particular interval is nonzero.\n",
    "\n",
    "> The **probability distribution of a continuous random variabl**e is a function that describes the probability of the variable taking on different values. The most common probability distribution for continuous random variables is the **normal distribution**, which is also known as the Gaussian distribution.\n",
    "\n",
    "> examples of continuous random variables:\n",
    "> * The height of a person\n",
    "> * The weight of an object\n",
    "> * The time it takes to complete a task\n",
    "> * The temperature on a given day\n",
    "> * The amount of rainfall in a given month\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495a476d",
   "metadata": {},
   "source": [
    "## 7. What are Bernoulli distributions? What is the formula of it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2623b3",
   "metadata": {},
   "source": [
    "> A **Bernoulli distribution** is a discrete probability distribution that takes on only two values, typically 0 and 1. The probability of a Bernoulli variable taking on a value of 1 is denoted by p, and the probability of it taking on a value of 0 is denoted by q. \n",
    "\n",
    ">The formula for the Bernoulli distribution is as follows: <br>\n",
    "```\n",
    "P(X = 1) = p\n",
    "P(X = 0) = q\n",
    "```               \n",
    "                where:\n",
    "                    P(X = 1) is the probability of the Bernoulli variable taking on a value of 1.\n",
    "                    P(X = 0) is the probability of the Bernoulli variable taking on a value of 0.\n",
    "                    p is the probability of success.\n",
    "                    q is the probability of failure.\n",
    "\n",
    "> examples of Bernoulli distributions:\n",
    "> * The outcome of a coin flip.\n",
    "> * The success or failure of a medical test.\n",
    "> * The presence or absence of a disease.\n",
    "> * The click-through rate on an advertisement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc52f2fd",
   "metadata": {},
   "source": [
    "## 8. What is binomial distribution? What is the formula?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbd99df",
   "metadata": {},
   "source": [
    "> The **binomial distribution** is a discrete probability distribution that describes the probability of getting a certain number of successes in a sequence of independent trials. Each trial has two possible outcomes, which we typically call \"success\" and \"failure.\" The probability of success is denoted by p, and the probability of failure is denoted by q.\n",
    "\n",
    "> The formula for the binomial distribution is as follows: <br>\n",
    "```P(X=k) = nCk * p^k * q^(n-k)```\n",
    "\n",
    "                where:\n",
    "\n",
    "                    P(X=k) is the probability of getting k successes in n trials.\n",
    "                    nCk is the combination of n things taken k at a time.\n",
    "                    p is the probability of success.\n",
    "                    q is the probability of failure.\n",
    "\n",
    "> examples of binomial distributions:\n",
    "> * The number of heads in 10 coin flips.\n",
    "> * The number of people who test positive for a disease in a sample of 100 people.\n",
    "> * The number of customers who click on an advertisement in a sample of 1000 customers.\n",
    "> * The number of times a die lands on 6 in 10 rolls.\n",
    "> * The number of times a basketball player makes a free throw in 10 attempts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e235823e",
   "metadata": {},
   "source": [
    "## 9. What is Poisson distribution? What is the formula?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466fdcdf",
   "metadata": {},
   "source": [
    "> The **Poisson distribution** is a discrete probability distribution that describes the probability of the occurrence of a certain number of events in a fixed interval of time or space. The Poisson distribution is often used to model the number of phone calls received in a call center per hour, the number of accidents on a highway per day, or the number of errors in a software program.\n",
    "\n",
    "> The formula for the Poisson distribution is as follows:<br>\n",
    "```P(X = k) = λ^k * e^-λ / k!```\n",
    "\n",
    "                where:\n",
    "\n",
    "                    P(X = k) is the probability of k events occurring in the interval.\n",
    "                    λ is the average number of events that occur in the interval.\n",
    "                    k is the number of events that occur in the interval.\n",
    "                    e is the base of the natural logarithm.\n",
    "                    ! is the factorial symbol.\n",
    "\n",
    "> examples of Poisson distributions:\n",
    "> * The number of phone calls received in a call center per hour.\n",
    "> * The number of accidents on a highway per day.\n",
    "> * The number of errors in a software program.\n",
    "> * The number of customers who visit a website per day.\n",
    "> * The number of bacteria in a sample of water.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662cc884",
   "metadata": {},
   "source": [
    "## 10. Define covariance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1737510",
   "metadata": {},
   "source": [
    "> **Covariance** is a measure of how two variables are related to each other. It is calculated as the average of the product of the deviations from the mean for two variables. The formula for covariance is as follows: <br>\n",
    "```Cov(X, Y) = ∑(X - μx)(Y - μy) / n```\n",
    "\n",
    "                where:\n",
    "\n",
    "                    Cov(X, Y) is the covariance between variables X and Y.\n",
    "                    ∑ is the sum of the values.\n",
    "                    (X - μx) is the deviation of X from its mean, μx.\n",
    "                    (Y - μy) is the deviation of Y from its mean, μy.\n",
    "                    n is the number of observations.\n",
    "\n",
    "> Covariance can be positive or negative. A **positive covariance** indicates that the two variables tend to move in the same direction, while a **negative covariance** indicates that the two variables tend to move in opposite directions.\n",
    "\n",
    "> The **magnitude of covariance** indicates the strength of the relationship between two variables. A larger covariance indicates a stronger relationship, while a smaller covariance indicates a weaker relationship.\n",
    "\n",
    ">  examples of covariance:\n",
    "> * The covariance between the height and weight of a person is positive. This indicates that taller people tend to be heavier, on average.\n",
    "> * The covariance between the price of a stock and the volume of trading in the stock is negative. This indicates that when the price of a stock goes up, the volume of trading tends to go down, and vice versa.\n",
    "> * The covariance between the number of phone calls received by a call center and the time of day is positive. This indicates that more phone calls are received during certain times of the day, such as during the morning and evening.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed54091",
   "metadata": {},
   "source": [
    "## 11. Define correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a56bbd",
   "metadata": {},
   "source": [
    "> **Correlation** is a measure of the strength and direction of the linear relationship between two variables. **Correlation** is calculated as the **Pearson correlation coefficient**, which is a number between -1 and 1.The magnitude of the correlation coefficient indicates the strength of the relationship between the two variables. \n",
    "\n",
    "> examples of correlation:\n",
    "> * The correlation between the height and weight of a person is positive and moderately strong. This indicates that taller people tend to be heavier, on average.\n",
    "> * The correlation between the price of a stock and the volume of trading in the stock is negative and moderately strong. This indicates that when the price of a stock goes up, the volume of trading tends to go down, and vice versa.\n",
    "> * The correlation between the number of phone calls received by a call center and the time of day is positive and weak. This indicates that more phone calls are received during certain times of the day, such as during the morning and evening, but the relationship is not very strong.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3032e5c5",
   "metadata": {},
   "source": [
    "## 12. Define sampling with replacement. Give example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f0d659",
   "metadata": {},
   "source": [
    ">  **Sampling with replacement** is a statistical technique where each member of a population has an equal chance of being selected for the sample, and each member can be selected more than once. This means that the same member of the population could be selected multiple times for the sample. <br>\n",
    "> Sampling with replacement is often used when the population is small or when the sample size is small. It is also used when the order of the sample does not matter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5380b1fd",
   "metadata": {},
   "source": [
    "## 13. What is sampling without replacement? Give example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9649b6fe",
   "metadata": {},
   "source": [
    "> **Sampling without replacement** is a statistical technique where each member of a population has an equal chance of being selected for the sample, but each member can only be selected once. This means that once a member of the population is selected for the sample, they cannot be selected again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2b0586",
   "metadata": {},
   "source": [
    "## 14. What is hypothesis? Give example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15709d3b",
   "metadata": {},
   "source": [
    "> **Hypothesis** refers to a proposed explanation or prediction that can be tested and evaluated through empirical evidence.\n",
    "A hypothesis can be either null or alternative. The **null hypothesis** is a statement that there is no relationship between the variables. The **alternative hypothesis** is a statement that there is a relationship between the variables.\n",
    "\n",
    "> For example, let's say we are interested in the relationship between smoking and lung cancer. we might hypothesize that smoking is associated with an increased risk of lung cancer. This would be the alternative hypothesis. The null hypothesis would be that there is no association between smoking and lung cancer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7924be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e228c32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
